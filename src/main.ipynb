{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias necesarias:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos a usar\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Otros objetos de sklearn a usar\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Librerias complementarias\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar visualización y desactivar warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recolección de la data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del dataset\n",
    "df = pd.read_csv(\"raw_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparación / preprocesamiento de la data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Eliminación de características redundantes o innecesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicados\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Limpieza de filas nulas, vacías o con error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores nulos con pd.NA para luego borrarlos:\n",
    "\n",
    "df.replace([\"\", \" \", \"?\", \"None\", \"N/A\", \"na\"], pd.NA, inplace=True)\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "df_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Encoder o codificador a las características no numéricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de valores categóricos en valores númericos:\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df[\"smoker\"].replace({\"yes\": 1, \"no\": 0}, inplace=True)\n",
    "df[\"sex\"].replace({\"male\": 1, \"female\": 0}, inplace=True)\n",
    "df[\"region\"] = label_encoder.fit_transform(df[\"region\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Normalizar y estandarizar la data con un escalador de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas númericas\n",
    "num_data = df.select_dtypes(include=\"number\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(num_data)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=num_data.columns)\n",
    "\n",
    "# Obtener el nuevo dataset escalado\n",
    "df = df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis descriptivo de la data (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Analisis de la data con gráficas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df, x=df[\"age\"], kde=True, color=\"skyblue\")\n",
    "plt.title(\"Distribución de la edad de los contratistas\", fontsize=16)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = f.add_subplot(121)\n",
    "sns.distplot(df[(df.smoker == 1)][\"charges\"], color=\"b\", ax=ax)\n",
    "ax.set_title(\"Distribución de cargos para fumadores\")\n",
    "\n",
    "ax = f.add_subplot(122)\n",
    "sns.distplot(df[(df.smoker == 0)][\"charges\"], color=\"r\", ax=ax)\n",
    "ax.set_title(\"Distribución de cargos para fumadores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.lineplot(data=df, x=df[\"age\"], y=df[\"children\"], color=\"skyblue\")\n",
    "plt.title(\"Distribución de la edad de los contratistas.\", fontsize=16)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Interpretación las estadísticas de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.catplot(x=\"smoker\", kind=\"count\", hue=\"sex\", palette=\"pink\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(\n",
    "    data=data[data[\"sex\"] == 1], x=data[\"smoker\"], y=\"charges\", palette=\"magma\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Interpretación de patrones de los datos con consultas y métodos de visualización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"charges\"] = df[\"charges\"].round()\n",
    "df.groupby([df[\"sex\"], df[\"smoker\"], df[\"region\"]])[\"charges\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"age\"] < 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    data=df[((df[\"age\"] < 25) & (df[\"smoker\"] == 1) & (df[\"sex\"] == 0))],\n",
    "    x=\"age\",\n",
    "    y=\"charges\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=df[((df[\"age\"] < 25) & (df[\"smoker\"] == 0) & (df[\"sex\"] == 0))],\n",
    "    x=\"age\",\n",
    "    y=\"charges\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data[data[\"smoker\"] == 1], x=\"age\", y=\"charges\", color=\"m\")\n",
    "sns.scatterplot(data[data[\"smoker\"] == 1], x=\"age\", y=\"charges\", color=\"r\")\n",
    "sns.scatterplot(data[data[\"smoker\"] == 0], x=\"age\", y=\"charges\", color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"charges\", hue=\"smoker\", data=data, palette=\"inferno_r\")\n",
    "ax.set_title(\"Smokers and non-smokers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data, x=data[\"region\"], y=data[\"charges\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.title(\"Distribution of bmi\")\n",
    "ax = sns.distplot(data[\"bmi\"], color=\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data, x=\"bmi\", y=\"charges\", color=\"c\", hue=\"smoker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = f.add_subplot(121)\n",
    "sns.distplot(df[(df.bmi >= 3)][\"charges\"], color=\"b\", ax=ax)\n",
    "ax.set_title(\"Distribution of charges for Bmi >= 30\")\n",
    "\n",
    "ax = f.add_subplot(122)\n",
    "sns.distplot(df[(df.bmi <= 30)][\"charges\"], color=\"c\", ax=ax)\n",
    "ax.set_title(\"Distribution of charges for Bmi >= 30\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x=\"smoker\",\n",
    "    kind=\"count\",\n",
    "    palette=\"rainbow\",\n",
    "    hue=\"sex\",\n",
    "    data=data[(data.children > 0)],\n",
    ")\n",
    "ax.set_title(\"Smokers and non-smokers who have childrens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[(df.children >= 3)][\"charges\"], color=\"b\", kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[(df.children < 3)][\"charges\"], color=\"c\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de entrada (X) y de salida (y)\n",
    "X = df.drop(\"charges\", axis=1)\n",
    "y = df[\"charges\"]\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba: (80% entrenamiento y 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Ordinary Least Squares Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ols(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de regresión lineal (OLS).\n",
    "\n",
    "    Este método estima los coeficientes de manera que se minimice\n",
    "    la suma de los errores cuadráticos (mínimos cuadrados).\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario con las métricas 'R2' y 'MSE' sobre el conjunto de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    global ols_model\n",
    "\n",
    "    ols_model = LinearRegression()\n",
    "    ols_model.fit(X_train, y_train)\n",
    "    y_test_pred = ols_model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2\": ols_model.score(X_test, y_test),\n",
    "        \"MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "    }\n",
    "\n",
    "    print(\"Ordinary Least Squares Regression:\")\n",
    "    print(\"  R² Score:\", metrics[\"R2\"])\n",
    "    print(\"  MSE:\", metrics[\"MSE\"])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "ols_metrics = run_ols(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción:\n",
    "- Este modelo es la regresión lineal clásica que estima los coeficientes minimizando la suma de los errores cuadráticos.\n",
    "\n",
    "Comentarios:\n",
    "- Es el modelo base y sirve como referencia para comparar el desempeño de modelos más complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Ridge Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ridge(X_train, y_train, X_test, y_test, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de Ridge Regression.\n",
    "\n",
    "    Ridge agrega un término de penalización (L2) al proceso de\n",
    "    minimización de errores, ayudando a evitar el sobreajuste.\n",
    "\n",
    "    Parámetros:\n",
    "        alpha (float): Hiperparámetro que controla la regularización.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario con las métricas 'R2' y 'MSE' sobre el conjunto de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    global ridge_model\n",
    "\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    y_test_pred = ridge_model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2\": ridge_model.score(X_test, y_test),\n",
    "        \"MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "    }\n",
    "\n",
    "    print(\"Ridge Regression:\")\n",
    "    print(\"  R² Score:\", metrics[\"R2\"])\n",
    "    print(\"  MSE:\", metrics[\"MSE\"])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "ridge_metrics = run_ridge(X_train, y_train, X_test, y_test, alpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción:\n",
    "- Ridge agrega un término de penalización (L2) a la función de pérdida, lo que ayuda a reducir el sobreajuste y manejar la multicolinealidad.\n",
    "\n",
    "Hiperparámetros clave:\n",
    "- alpha: Controla la intensidad de la regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Bayesian Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bayesian(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de Bayesian Ridge Regression.\n",
    "\n",
    "    Este modelo aplica un enfoque bayesiano para estimar los parámetros,\n",
    "    lo que permite incorporar la incertidumbre de las estimaciones.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario con las métricas 'R2' y 'MSE' sobre el conjunto de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    global bayesian_model\n",
    "\n",
    "    bayesian_model = BayesianRidge()\n",
    "    bayesian_model.fit(X_train, y_train)\n",
    "    y_test_pred = bayesian_model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2\": bayesian_model.score(X_test, y_test),\n",
    "        \"MSE\": mean_squared_error(y_test, y_test_pred),  # type: ignore\n",
    "    }\n",
    "\n",
    "    print(\"Bayesian Regression:\")\n",
    "    print(\"  R² Score:\", metrics[\"R2\"])\n",
    "    print(\"  MSE:\", metrics[\"MSE\"])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "bayesian_metrics = run_bayesian(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción:\n",
    "- Utiliza un enfoque bayesiano para estimar los parámetros del modelo, incorporando la incertidumbre inherente en las estimaciones y permitiendo una interpretación probabilística.\n",
    "\n",
    "Comentarios:\n",
    "- Es especialmente útil cuando se requiere una medida de la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Lasso Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lasso(X_train, y_train, X_test, y_test, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de Lasso Regression.\n",
    "\n",
    "    Lasso utiliza una penalización L1, lo que puede hacer que algunos\n",
    "    coeficientes se vuelvan exactamente cero, realizando una selección de características.\n",
    "\n",
    "    Parámetros:\n",
    "        alpha (float): Hiperparámetro que controla la intensidad de la regularización.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario con las métricas 'R2' y 'MSE' sobre el conjunto de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    global lasso_model\n",
    "\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    y_test_pred = lasso_model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2\": lasso_model.score(X_test, y_test),\n",
    "        \"MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "    }\n",
    "\n",
    "    print(\"Lasso Regression:\")\n",
    "    print(\"  R² Score:\", metrics[\"R2\"])\n",
    "    print(\"  MSE:\", metrics[\"MSE\"])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "lasso_metrics = run_lasso(X_train, y_train, X_test, y_test, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción:\n",
    "- Emplea una penalización L1 que puede reducir algunos coeficientes a cero, realizando así una selección de características de manera implícita.\n",
    "\n",
    "Hiperparámetros clave:\n",
    "- alpha: Controla la intensidad de la penalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Nearest Neighbors Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(X_train, y_train, X_test, y_test, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de K-Nearest Neighbors Regression.\n",
    "\n",
    "    El modelo predice el valor de la etiqueta basándose en el promedio de los\n",
    "    K vecinos más cercanos en el espacio de características.\n",
    "\n",
    "    Parámetros:\n",
    "        n_neighbors (int): Número de vecinos a considerar.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario con las métricas 'R2' y 'MSE' sobre el conjunto de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    global knn_model\n",
    "\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_test_pred = knn_model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2\": knn_model.score(X_test, y_test),\n",
    "        \"MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "    }\n",
    "\n",
    "    print(\"Nearest Neighbors Regression:\")\n",
    "    print(\"  R² Score:\", metrics[\"R2\"])\n",
    "    print(\"  MSE:\", metrics[\"MSE\"])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "knn_metrics = run_knn(X_train, y_train, X_test, y_test, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción:\n",
    "- Predice la etiqueta de una instancia basándose en el promedio de los K vecinos más cercanos en el espacio de características.\n",
    "\n",
    "Hiperparámetros clave:\n",
    "- n_neighbors: Número de vecinos considerados en la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Random Forest Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest(X_train, y_train, X_test, y_test, n_estimators=100):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de Random Forest Regression.\n",
    "\n",
    "    Random Forest es un conjunto (ensemble) de árboles de decisión que\n",
    "    mejora la precisión y controla el sobreajuste mediante la agregación de múltiples predicciones.\n",
    "\n",
    "    Parámetros:\n",
    "        n_estimators (int): Número de árboles en el bosque.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario con las métricas 'R2' y 'MSE' sobre el conjunto de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    global rf_model\n",
    "\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators, random_state=1, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2\": rf_model.score(X_test, y_test),\n",
    "        \"MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "    }\n",
    "\n",
    "    print(\"Random Forest Regression:\")\n",
    "    print(\"  R² Score:\", metrics[\"R2\"])\n",
    "    print(\"  MSE:\", metrics[\"MSE\"])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "rf_metrics = run_random_forest(X_train, y_train, X_test, y_test, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción:\n",
    "- Es un método ensemble que utiliza múltiples árboles de decisión para mejorar la robustez y la precisión del modelo mediante la agregación de predicciones.\n",
    "\n",
    "Hiperparámetros clave:\n",
    "- n_estimators: Número de árboles en el bosque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - SVM (Support Vector Machine) Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svr(X_train, y_train, X_test, y_test, kernel=\"rbf\", C=1.0, epsilon=0.2):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de SVM Regression.\n",
    "\n",
    "    El modelo SVR (Support Vector Regression) intenta encontrar una función\n",
    "    que tenga a lo sumo una desviación epsilon de las observaciones reales,\n",
    "    usando núcleos para capturar relaciones no lineales.\n",
    "\n",
    "    Parámetros:\n",
    "        kernel (str): Tipo de kernel a utilizar.\n",
    "        C (float): Parámetro de regularización.\n",
    "        epsilon (float): Margen dentro del cual no se penalizan errores.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario con las métricas 'R2' y 'MSE' sobre el conjunto de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    global svr_model\n",
    "\n",
    "    svr_model = SVR(kernel=kernel, C=C, epsilon=epsilon) # type: ignore\n",
    "    svr_model.fit(X_train, y_train)\n",
    "    y_test_pred = svr_model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2\": svr_model.score(X_test, y_test),\n",
    "        \"MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "    }\n",
    "\n",
    "    print(\"SVM Regression:\")\n",
    "    print(\"  R² Score:\", metrics[\"R2\"])\n",
    "    print(\"  MSE:\", metrics[\"MSE\"])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "svr_metrics = run_svr(\n",
    "    X_train, y_train, X_test, y_test, kernel=\"rbf\", C=1.0, epsilon=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción:\n",
    "- Busca encontrar una función que tenga a lo sumo una desviación epsilon de los valores reales, utilizando núcleos (kernel) para capturar relaciones no lineales.\n",
    "\n",
    "Hiperparámetros clave:\n",
    "- kernel: Tipo de función kernel (por ejemplo, \"rbf\").\n",
    "- C: Parámetro de regularización.\n",
    "- epsilon: Tolerancia para los errores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Neural Network MLP Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp(X_train, y_train, X_test, y_test, hidden_layer_sizes=(100,), max_iter=500):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de MLP Regressor.\n",
    "\n",
    "    Se utiliza una red neuronal (MLP) para modelar relaciones complejas.\n",
    "    El hiperparámetro 'hidden_layer_sizes' define la arquitectura de la red.\n",
    "\n",
    "    Parámetros:\n",
    "        hidden_layer_sizes (tuple): Número de neuronas en cada capa oculta.\n",
    "        max_iter (int): Número máximo de iteraciones para el entrenamiento.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Diccionario con las métricas 'R2' y 'MSE' sobre el conjunto de prueba.\n",
    "    \"\"\"\n",
    "\n",
    "    global mlp_model\n",
    "\n",
    "    mlp_model = MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, random_state=1\n",
    "    )\n",
    "\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    y_test_pred = mlp_model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2\": mlp_model.score(X_test, y_test),\n",
    "        \"MSE\": mean_squared_error(y_test, y_test_pred),\n",
    "    }\n",
    "    \n",
    "    print(\"Neural Network MLP Regression:\")\n",
    "    print(\"  R² Score:\", metrics[\"R2\"])\n",
    "    print(\"  MSE:\", metrics[\"MSE\"])\n",
    "    return metrics\n",
    "\n",
    "\n",
    "mlp_metrics = run_mlp(\n",
    "    X_train, y_train, X_test, y_test, hidden_layer_sizes=(100,), max_iter=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción:\n",
    "- Utiliza una red neuronal de perceptrones multicapa (MLP) para modelar relaciones complejas entre las variables.\n",
    "\n",
    "Hiperparámetros clave:\n",
    "- hidden_layer_sizes: Define la arquitectura de la red (número de neuronas en cada capa oculta).\n",
    "- max_iter: Número máximo de iteraciones para el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validación y testeo del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se evalúa la capacidad de generalización del modelo, asegurando la robustez del modelo.\n",
    "\n",
    "Se ha dividido el conjunto de datos en un 80% para entrenamiento y un 20% para prueba. Además, se ha implementado una validación cruzada k-fold (k=5) para estimar la estabilidad del desempeño del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Comparación de Modelos y Pruebas de Robustez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados de cada modelo\n",
    "results = {\n",
    "    \"Ordinary Least Squares\": ols_metrics,\n",
    "    \"Ridge Regression\": ridge_metrics,\n",
    "    \"Bayesian Regression\": bayesian_metrics,\n",
    "    \"Lasso Regression\": lasso_metrics,\n",
    "    \"Nearest Neighbors Regression\": knn_metrics,\n",
    "    \"Random Forest Regression\": rf_metrics,\n",
    "    \"SVM Regression\": svr_metrics,\n",
    "    \"Neural Network MLP Regression\": mlp_metrics\n",
    "}\n",
    "\n",
    "# Convertir los resultados en un DataFrame para una mejor visualización\n",
    "results_df = pd.DataFrame(results).T  # Transponer para que cada fila sea un modelo\n",
    "results_df = results_df.rename(columns={\"R2\": \"R² Score\", \"MSE\": \"MSE\"})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Validación del modelo de LinearRegression:\n",
    "scores = cross_val_score(ols_model, X, y, cv=5, scoring='r2')\n",
    "print(\"R² en validación cruzada: %.2f ± %.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Análisis de Residuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = ols_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_pred_test, y_test - y_pred_test, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicciones\")\n",
    "plt.ylabel(\"Residuos\")\n",
    "plt.title(\"Gráfico de residuos vs. predicciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Despliegue del modelo y comprobación con data recién creada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para desplegar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desplegar_modelo(model, new_data_path:str):\n",
    "    \"\"\"\n",
    "    Carga un nuevo archivo CSV, lo preprocesa de forma similar\n",
    "    al dataset de entrenamiento y realiza predicciones con el modelo dado.\n",
    "\n",
    "    Parámetros:\n",
    "        model: Modelo entrenado (por ejemplo, el mejor modelo seleccionado).\n",
    "        new_data_path (str): Ruta al archivo CSV con datos nuevos.\n",
    "\n",
    "    Retorna:\n",
    "        np.array: Predicciones realizadas por el modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lectura del nuevo dataset\n",
    "    new_df = pd.read_csv(new_data_path)\n",
    "\n",
    "    # - Preprocesamiento:\n",
    "\n",
    "    new_df.drop_duplicates(inplace=True)\n",
    "    new_df.replace([\"\", \" \", \"?\", \"None\", \"N/A\", \"na\"], pd.NA, inplace=True)\n",
    "    new_df_cleaned = new_df.dropna()\n",
    "    new_df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Codificar variables categóricas\n",
    "    new_df[\"smoker\"].replace({\"yes\": 1, \"no\": 0}, inplace=True)\n",
    "    new_df[\"sex\"].replace({\"male\": 1, \"female\": 0}, inplace=True)\n",
    "    new_df[\"region\"] = label_encoder.fit_transform(new_df[\"region\"])\n",
    "\n",
    "    # Estandarizar utilizando el mismo escalador\n",
    "    new_num_data = new_df.select_dtypes(include=\"number\")\n",
    "    new_scaled_data = scaler.fit_transform(new_num_data)\n",
    "    new_df_scaled = pd.DataFrame(new_scaled_data, columns=new_num_data.columns)\n",
    "    new_df = new_df_scaled\n",
    "\n",
    "    # Separar las entradas\n",
    "    X_new = new_df.drop(\"charges\", axis=1)\n",
    "\n",
    "    # Realizar predicciones\n",
    "    predictions = model.predict(X_new)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir el mejor modelo y la ruta al nuevo dataset\n",
    "mejor_modelo = rf_model\n",
    "nuevo_dataset = \"ruta_al_nuevo_dataset.csv\"\n",
    "\n",
    "# Obtener nuevas predicciones\n",
    "predicciones = desplegar_modelo(mejor_modelo, nuevo_dataset)\n",
    "print(predicciones)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
